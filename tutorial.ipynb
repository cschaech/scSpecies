{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import muon as mu\n",
    "import scanpy as sc\n",
    "\n",
    "path = \"C:/Users/cleme/Desktop/Github/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step we load the context and target dataset as `.h5ad` files. We will use a subset of the mouse and human liver cell atlas.  \n",
    "\n",
    "The data is preprocessed to 4000 highly variable genes, cells belonging to large cell types are randomly sampled to reduce their size  \n",
    "and potential labeling conflicts between precise and rough labels are removed. The full datasets can be downloaded at https://www.livercellatlas.org/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_adata = sc.read_h5ad(path+\"dataset/mouse_liver_filtered.h5ad\")\n",
    "target_adata = sc.read_h5ad(path+\"dataset/human_liver_filtered.h5ad\")\n",
    "\n",
    "context_adata.X = context_adata.X.astype('float32')\n",
    "target_adata.X = target_adata.X.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the key under which the cell and batch label for the context and target dataset are saved.  \n",
    "The cell labels for the target dataset are used only for plotting and not needed during training.  \n",
    "If the target cell labels are unknown they can be set to `target_cell_key = None`.  \n",
    "\n",
    "We print the cell labels common to both datasets and the cell labels unique to context and target dataset.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_batch_key = 'sample'\n",
    "context_cell_key = 'cell_type_fine'\n",
    "\n",
    "target_batch_key = 'sample'\n",
    "target_cell_key = 'cell_type_fine'\n",
    "\n",
    "joint_labels = set(context_adata.obs[context_cell_key]).intersection(set(target_adata.obs[target_cell_key]))  \n",
    "unique_context_labels = set(context_adata.obs[context_cell_key]).difference(set(target_adata.obs[target_cell_key]))  \n",
    "unique_target_labels = set(target_adata.obs[target_cell_key]).difference(set(context_adata.obs[context_cell_key]))   \n",
    "\n",
    "print('Cell labels occuring in both datasets: ', sorted(list(joint_labels)))\n",
    "print('Unique context cell labels:', sorted(list(unique_context_labels)))\n",
    "print('Unique target cell labels:', sorted(list(unique_target_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the `muon.MuData` dataset (https://muon.readthedocs.io/en/latest/) which scPecies uses during training.  \n",
    "Muon lets us define container for multimodal data.  \n",
    "One modality will be our context species dataset and one (or possibly more) will contain the target species dataset(s).  \n",
    "We instantiate a preprocessing class and register context and target `anndata.AnnData` datasets.  \n",
    "\n",
    "\n",
    "This also performs the data-level nearest neighbor search.  \n",
    "We further reduce the dimensionality to the 2500 most highly variable genes.  \n",
    "When performing an alignment for multiple species `.setup_target_adata` can be run multiple times.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import create_mdata\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "preprocess = create_mdata(context_adata, context_batch_key, context_cell_key, context_dataset_name='mouse', context_n_top_genes=2500)\n",
    "preprocess.setup_target_adata(target_adata, target_batch_key, target_cell_key, target_dataset_name='human', target_n_top_genes=2500)\n",
    "preprocess.save_mdata(path, 'liver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the context and target scVI models by instantiating the scPecies class.  \n",
    "We recommend using an NVIDIA GPU during training. CPU training can be slow, and Apple Silicon runs into errors when trying to compute the log-gamma function for the scVI loss.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import scPecies\n",
    "import torch\n",
    "import muon as mu\n",
    "\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mdata = mu.read_h5mu(path+\"dataset/liver.h5mu\")\n",
    "\n",
    "model = scPecies(device, \n",
    "                mdata, \n",
    "                path,\n",
    "                context_dataset_key = 'mouse', \n",
    "                target_dataset_key = 'human', \n",
    "                context_data_distr = 'nb',    \n",
    "                target_data_distr = 'nb',                                    \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train and evaluate the context scVI model.  \n",
    "The model parameters are automatically saved to the specified path and the latent representations saved in the `muon.MuData` object at the context modality in the `.obsm` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_context(60, early_stopping=False)\n",
    "model.eval_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we train and evaluate the target scVI model using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_target(60, early_stopping=False)\n",
    "model.eval_target()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we can predict cell labels using the aligned representation.  \n",
    "We can compare the quality of the predicted labels with the data level nearest neighbor search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pred_labels_nns_aligned_latent_space()\n",
    "model.compute_metrics() \n",
    "\n",
    "knn_acc = round(model.mdata.mod[model.target_dataset_key].uns['metrics']['balanced_accuracy_score_nns_hom_genes']*100,1)\n",
    "latent_acc = round(model.mdata.mod[model.target_dataset_key].uns['metrics']['balanced_accuracy_score_nns_aligned_latent_space']*100,1)\n",
    "\n",
    "knn_adj = round(model.mdata.mod[model.target_dataset_key].uns['metrics']['adjusted_rand_score_nns_hom_genes'],3)\n",
    "latent_adj = round(model.mdata.mod[model.target_dataset_key].uns['metrics']['adjusted_rand_score_nns_aligned_latent_space'],3)\n",
    "\n",
    "knn_mis = round(model.mdata.mod[model.target_dataset_key].uns['metrics']['adjusted_mutual_info_score_nns_hom_genes'],3)\n",
    "latent_mis = round(model.mdata.mod[model.target_dataset_key].uns['metrics']['adjusted_mutual_info_score_nns_aligned_latent_space'],3)\n",
    "\n",
    "# prediction dataframes of the aligned latent knn search and the data-level knn search.\n",
    "#model.mdata.mod[model.target_dataset_key].uns['prediction_df_nns_aligned_latent_space']\n",
    "#model.mdata.mod[model.target_dataset_key].uns['prediction_df_nns_hom_genes']\n",
    "\n",
    "\n",
    "# predicted cell labels of the aligned latent knn search and the data-level knn search.\n",
    "#model.mdata.mod[model.target_dataset_key].obs['label_nns_aligned_latent_space']\n",
    "#model.mdata.mod[model.target_dataset_key].obs['label_nns_hom_genes']\n",
    "\n",
    "\n",
    "print('\\n Accuracy: data-level knn-search: {}%, latent knn-search: {}%.'.format(knn_acc, latent_acc))\n",
    "print('\\n Adjusted Rand iIndex: data-level knn-search: {}, latent knn-search: {}.'.format(knn_adj, latent_adj))\n",
    "print('\\n Mutual information: data-level knn-search: {}, latent knn-search: {}.'.format(knn_mis, latent_mis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the results for the liver cell dataset with provided functions.  \n",
    "On other datasets these functions should be modified or scanpy functions like `scanpy.pl.umap` should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_utils import plot_umap, bar_plot\n",
    "\n",
    "plot_umap(model)\n",
    "bar_plot(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the difference in modeled gene expression can be analyzed by comparing the log2-fold change in normalized gene expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_utils import plot_lfc\n",
    "\n",
    "model.compute_logfold_change(lfc = 1)\n",
    "\n",
    "# dataframe of the log2-fold change and corresponding probabilities.\n",
    "# model.mdata.mod[model.context_dataset_key].uns['lfc_df']\n",
    "# model.mdata.mod[model.context_dataset_key].uns['prob_df']\n",
    "\n",
    "plot_lfc(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c21f28c68d3991a272eb9e65318d851a361f99ccab42ab97599ef8d4a966313"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
